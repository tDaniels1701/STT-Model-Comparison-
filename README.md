# STT-Model-Comparison-
STT Model Comparison 

## Background
This study aims to compare two novel voice recognition models, Deepgram Nova-2 and Whisper V3, in their ability to accurately convert speech-to-text in medical student MDM during clinical case presentations. The implementation of these models into a lexical analysis program has the potential to concurrently assess thousands of presentations in seconds, as opposed to the multiple days needed by clinicians who grade by hand. We plan to utilize in-house data from the Simulation Center, that  previously de-identified, to evaluate and compare two models, Deepgram Nova-2 and Whisper V3 to a True Transcription. The True Transcription will be generated by student researchers and validated by an attending physician. This speech-to-text evaluation will rely primarily on word accuracy as compared to the True Transcription

## General Statistical Analysis
Approximately 154 previously de-identified Integrated Clinical Case (ICC) recordings were transcribed by student researchers each receiving approximately 40 transcriptions. Transcriptions were further validated by an attending physician and data scientist to maintain textual cleaning uniformity. These initial transcripts are considered True Transcriptions. All recordings were transcribed by Deepgram Nova-2 and Whisper V3, for comparison of STT. The textual output was cleaned for abbreviates, punctuation, grammar, and other textual impurities. Stop words using the Natural Language Toolkit (NLTK) python library were also stripped from the text.  This process was universally applied to both Whisper and Deepgram. Next, the textual output for the models were analyzed using Term Frequency Inverse Document Frequency (TFIDF). The textual output of the two STT models were then paired against the true transcription, generating standard Large Language Model (LLM) error metrics. The models were evaluated on seven of these metrics: 1. Jaccard Similarity, 2. Jaro-Winkler Distance, 3. Leveshtein Distance, 4. Word Error Rate, 5. Word Information Loss, 6. Match Error Rate, and 7. Character Error Rate. Essentially these metrics evaluate a STT model


